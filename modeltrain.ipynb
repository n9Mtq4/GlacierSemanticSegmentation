{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/karolzak/keras-unet/blob/master/notebooks/kz-whale-tails.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data/tiles/ls8\")\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "NETWORK_HEADS = 7\n",
    "\n",
    "MAX_X = 255\n",
    "# MAX_Y = 65535  # TODO: Tilegen outputs rgb image, not grayscale\n",
    "MAX_Y = 255\n",
    "\n",
    "BAND_DIRS = sorted(list(DATA_DIR.glob(\"B*\"))) # [::-1]  # reverse for rgb\n",
    "TRUTH_DIR = DATA_DIR / \"truth\"\n",
    "\n",
    "display(BAND_DIRS)\n",
    "display(list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_paths = list(TRUTH_DIR.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fname(fname):\n",
    "    # div by maxy, but mul by maxx in anticipation of preprocess_transform\n",
    "    truth = np.array(Image.open(TRUTH_DIR / fname)) # / (MAX_Y / MAX_X)\n",
    "    truth = truth.astype('uint8')\n",
    "    bands = np.asarray([np.array(Image.open(band_dir / fname)) for band_dir in BAND_DIRS])\n",
    "#     bands = bands[1:4] # [::-1]\n",
    "    mchannel = np.dstack(bands).astype('uint8')\n",
    "    return mchannel, truth\n",
    "\n",
    "def preprocess_transform(ds):\n",
    "    return (ds / MAX_X).astype('float32')\n",
    "\n",
    "def rgb_transform(ds):\n",
    "#     return ds # bands 4, 3, 2, -> rgb\n",
    "#     return np.flip(ds, 3)  # Bands 2, 3, 4 -> rgb\n",
    "    return np.flip(ds[:,:,:,1:4], 3)  # Bands 1, 2, 3, 4, 5, 7 -> rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(truth_paths[0].name)\n",
    "\n",
    "x0, y0 = read_fname(truth_paths[0].name)\n",
    "\n",
    "display(x0.shape)\n",
    "display(y0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_np = np.zeros(shape = (len(truth_paths), *x0.shape), dtype = 'uint8')\n",
    "msk_np = np.zeros(shape = (len(truth_paths), *y0.shape), dtype = 'uint8')\n",
    "\n",
    "for i, truth_path in enumerate(truth_paths):\n",
    "    img, truth = read_fname(truth_path.name)\n",
    "    img_np[i] = img\n",
    "    msk_np[i] = truth\n",
    "\n",
    "msk_np = msk_np.reshape(msk_np.shape[0], msk_np.shape[1], msk_np.shape[2], 1)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "display(f'{img_np.shape=}')\n",
    "display(f'{msk_np.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "display(img_np.min())\n",
    "display(img_np.max())\n",
    "display(msk_np.min())\n",
    "display(msk_np.max())\n",
    "\n",
    "plot_imgs(org_imgs=rgb_transform(img_np[:10]) / 255, mask_imgs=msk_np[:10] / 255, nm_img_to_plot=5, figsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: this requires a copy - use different sets for train and val to limit memory\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(img_np, msk_np, test_size=0.05, random_state=0)\n",
    "\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_val: \", x_val.shape)\n",
    "print(\"y_val: \", y_val.shape)\n",
    "\n",
    "input_shape = x_train[0].shape\n",
    "display(f'{input_shape=}')\n",
    "\n",
    "train_len = len(x_train)\n",
    "validation_len = len(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del img_np\n",
    "del msk_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = preprocess_transform(x_val)\n",
    "y_val = preprocess_transform(y_val)\n",
    "\n",
    "x_val_tf = tf.convert_to_tensor(x_val)\n",
    "y_val_tf = tf.convert_to_tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import get_augmented\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.preprocessing.image import NumpyArrayIterator\n",
    "from imgloader import NumpyArrayIterator\n",
    "\n",
    "img_gen_args = dict(\n",
    "    # rescale=1 / 255,\n",
    "    preprocessing_function=preprocess_transform,\n",
    "    rotation_range=360.,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=40,\n",
    "    zoom_range=0.2,\n",
    "    # brightness_range=[0.6,1.4],  # only works on 1 or 3 channel images\n",
    "    channel_shift_range=10.0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# train_gen = get_augmented(\n",
    "#     x_train, y_train, \n",
    "# #     x_val_tf, y_val_tf,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     data_gen_args = img_gen_args\n",
    "# )\n",
    "\n",
    "train_gen = NumpyArrayIterator(\n",
    "    x_train, y_train,\n",
    "    image_data_generator = ImageDataGenerator(**img_gen_args),\n",
    "    transform_img = preprocess_transform,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    dtype = 'float32',\n",
    "    network_heads = NETWORK_HEADS\n",
    ")\n",
    "\n",
    "# train_gen = get_augmented(\n",
    "#     x_train, y_train, batch_size=2,\n",
    "#     data_gen_args=dict(\n",
    "#         rotation_range=0.,\n",
    "#         width_shift_range=0.00,\n",
    "#         height_shift_range=0.00,\n",
    "#         shear_range=0,\n",
    "#         zoom_range=0.0,\n",
    "#         horizontal_flip=True,\n",
    "#         vertical_flip=True,\n",
    "#         fill_mode='constant'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# del x_train\n",
    "# del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_batch = next(train_gen)\n",
    "\n",
    "xx, yy = sample_batch\n",
    "\n",
    "if NETWORK_HEADS > 1:\n",
    "    yy = yy[0]\n",
    "\n",
    "print(xx.shape, yy.shape)\n",
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "\n",
    "# def preprocess_transform(ds):\n",
    "#     return (ds / MAX_X).astype('float32')\n",
    "\n",
    "# xx = preprocess_transform(xx)\n",
    "# yy = preprocess_transform(yy)\n",
    "\n",
    "print(xx.min())\n",
    "print(xx.max())\n",
    "print(yy.min())\n",
    "print(yy.max())\n",
    "\n",
    "plot_imgs(org_imgs=rgb_transform(xx), mask_imgs=yy, nm_img_to_plot=2, figsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from usquarednet import u2netp_block, u2net_block\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_unetp():\n",
    "    inputs = Input(input_shape)\n",
    "    sides = u2net_block(inputs)\n",
    "    model = Model(inputs=[inputs], outputs=sides)\n",
    "    return model\n",
    "\n",
    "model = create_unetp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bcdunet import BCDU_net_D3, BCDU_net_D1\n",
    "\n",
    "# input_shape = (512, 512, 3)\n",
    "# model = BCDU_net_D3(input_size=input_shape, afunc='swish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras_unet.models import custom_unet\n",
    "\n",
    "# # input_shape = (512, 512, 6)\n",
    "\n",
    "def create_model_unet():\n",
    "    model = custom_unet(\n",
    "        input_shape,\n",
    "        filters=8,\n",
    "        activation='swish',\n",
    "        use_batch_norm=True,\n",
    "        dropout=0.5,  # 0.3\n",
    "        dropout_change_per_layer=0.0,\n",
    "        use_attention=False,\n",
    "        use_squeeze_on_enc=False,\n",
    "        use_squeeze_on_dec=False,\n",
    "        num_layers=5,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# model = create_model_unet()\n",
    "\n",
    "# model = custom_unet(\n",
    "#     input_shape,\n",
    "#     filters=32,\n",
    "#     use_batch_norm=True,\n",
    "#     dropout=0.5,  # 0.3\n",
    "#     dropout_change_per_layer=0.0,\n",
    "#     use_attention=False,\n",
    "#     use_squeeze_on_enc=True,\n",
    "#     use_squeeze_on_dec=True,\n",
    "#     num_layers=5,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_trainchpt.h5'\n",
    "callback_checkpoint = ModelCheckpoint(\n",
    "    model_filename, \n",
    "    verbose=1, \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ailias/Focal-Loss-implement-on-Tensorflow/blob/master/focal_loss.py\n",
    "\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "def focal_loss(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    r\"\"\"Compute focal loss for predictions.\n",
    "        Multi-labels Focal loss formula:\n",
    "            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "    Args:\n",
    "     prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing the predicted logits for each class\n",
    "     target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing one-hot encoded classification targets\n",
    "     weights: A float tensor of shape [batch_size, num_anchors]\n",
    "     alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "     gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "    Returns:\n",
    "        loss: A (scalar) tensor representing the value of the loss function\n",
    "    \"\"\"\n",
    "    sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "    \n",
    "    # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "    \n",
    "    # For negative prediction, only need consider back part loss, front part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.math.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.math.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return tf.reduce_sum(per_entry_cross_ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance\n",
    "\n",
    "def closs(y_true, y_pred):\n",
    "    return 2 * jaccard_distance(y_true, y_pred) + tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "#     optimizer=Adam(learning_rate=0.0001),\n",
    "#     optimizer=\"adam\",\n",
    "    #optimizer=SGD(lr=0.01, momentum=0.99),\n",
    "    loss=NETWORK_HEADS * ['binary_crossentropy'],\n",
    "#     loss='binary_crossentropy',\n",
    "#     loss=jaccard_distance,\n",
    "#     loss=focal_loss,\n",
    "#     loss=closs,\n",
    "    metrics=[iou, iou_thresholded],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(model_filename)\n",
    "# model.load_weights('model_trainafter_ndsi_unet.h5')\n",
    "# model.load_weights('bcdu_net_d3_20201002_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_len // BATCH_SIZE,\n",
    "    epochs=200,\n",
    "    validation_data=(x_val_tf, y_val_tf),\n",
    "    validation_batch_size=BATCH_SIZE,\n",
    "    callbacks=[callback_checkpoint, tensorboard_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "plot_segm_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_trainafter.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(model_filename)\n",
    "# model.save('model.h5')\n",
    "model.load_weights('model_trainchpt_e183.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "if NETWORK_HEADS > 1:\n",
    "    y_pred = y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "display(len(x_val))\n",
    "plot_imgs(org_imgs=rgb_transform(x_val), mask_imgs=y_val, pred_imgs=y_pred, nm_img_to_plot=10, figsize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
