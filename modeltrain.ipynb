{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/karolzak/keras-unet/blob/master/notebooks/kz-whale-tails.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mixed precision\n",
    "\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DATA_DIR = Path(\"./data/tiles/ls8\")\n",
    "DATA_DIR = Path(\"/tmp/ls8\")\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "NETWORK_HEADS = 7\n",
    "\n",
    "MAX_X = 255\n",
    "# MAX_Y = 65535  # TODO: Tilegen outputs rgb image, not grayscale\n",
    "MAX_Y = 255\n",
    "\n",
    "BAND_DIRS = sorted(list(DATA_DIR.glob(\"B*\"))) # [::-1]  # reverse for rgb\n",
    "TRUTH_DIR = DATA_DIR / \"truth\"\n",
    "\n",
    "display(BAND_DIRS)\n",
    "display(list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_paths = list(TRUTH_DIR.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fname(fname):\n",
    "    # div by maxy, but mul by maxx in anticipation of preprocess_transform\n",
    "    truth = np.array(Image.open(TRUTH_DIR / fname)) # / (MAX_Y / MAX_X)\n",
    "    truth = truth.astype('uint8')\n",
    "    bands = np.asarray([np.array(Image.open(band_dir / fname)) for band_dir in BAND_DIRS])\n",
    "#     bands = bands[1:4] # [::-1]\n",
    "    mchannel = np.dstack(bands).astype('uint8')\n",
    "    return mchannel, truth\n",
    "\n",
    "def preprocess_transform(ds):\n",
    "    return (ds / MAX_X).astype('float32')\n",
    "\n",
    "def rgb_transform(ds):\n",
    "#     return ds # bands 4, 3, 2, -> rgb\n",
    "#     return np.flip(ds, 3)  # Bands 2, 3, 4 -> rgb\n",
    "    return np.flip(ds[:,:,:,1:4], 3)  # Bands 1, 2, 3, 4, 5, 7 -> rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(truth_paths[0].name)\n",
    "\n",
    "x0, y0 = read_fname(truth_paths[0].name)\n",
    "\n",
    "display(x0.shape)\n",
    "display(y0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_np = np.zeros(shape = (len(truth_paths), *x0.shape), dtype = 'uint8')\n",
    "msk_np = np.zeros(shape = (len(truth_paths), *y0.shape), dtype = 'uint8')\n",
    "\n",
    "for i, truth_path in enumerate(truth_paths):\n",
    "    img, truth = read_fname(truth_path.name)\n",
    "    img_np[i] = img\n",
    "    msk_np[i] = truth\n",
    "\n",
    "msk_np = msk_np.reshape(msk_np.shape[0], msk_np.shape[1], msk_np.shape[2], 1)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "display(f'{img_np.shape=}')\n",
    "display(f'{msk_np.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "display(img_np.min())\n",
    "display(img_np.max())\n",
    "display(msk_np.min())\n",
    "display(msk_np.max())\n",
    "\n",
    "plot_imgs(org_imgs=rgb_transform(img_np[:10]) / 255, mask_imgs=msk_np[:10] / 255, nm_img_to_plot=5, figsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: this requires a copy - use different sets for train and val to limit memory\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(img_np, msk_np, test_size=0.05, random_state=0)\n",
    "\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_val: \", x_val.shape)\n",
    "print(\"y_val: \", y_val.shape)\n",
    "\n",
    "input_shape = x_train[0].shape\n",
    "display(f'{input_shape=}')\n",
    "\n",
    "train_len = len(x_train)\n",
    "validation_len = len(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del img_np\n",
    "del msk_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = preprocess_transform(x_val)\n",
    "y_val = preprocess_transform(y_val)\n",
    "\n",
    "x_val_tf = tf.convert_to_tensor(x_val)\n",
    "y_val_tf = tf.convert_to_tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import get_augmented\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.preprocessing.image import NumpyArrayIterator\n",
    "from imgloader import NumpyArrayIterator\n",
    "\n",
    "img_gen_args = dict(\n",
    "    # rescale=1 / 255,\n",
    "    preprocessing_function=preprocess_transform,\n",
    "    rotation_range=360.,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=40,\n",
    "    zoom_range=0.2,\n",
    "    # brightness_range=[0.6,1.4],  # only works on 1 or 3 channel images\n",
    "    channel_shift_range=10.0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# train_gen = get_augmented(\n",
    "#     x_train, y_train, \n",
    "# #     x_val_tf, y_val_tf,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     data_gen_args = img_gen_args\n",
    "# )\n",
    "\n",
    "train_gen = NumpyArrayIterator(\n",
    "    x_train, y_train,\n",
    "    image_data_generator = ImageDataGenerator(**img_gen_args),\n",
    "    transform_img = preprocess_transform,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    dtype = 'float32',\n",
    "    network_heads = NETWORK_HEADS\n",
    ")\n",
    "\n",
    "# train_gen = get_augmented(\n",
    "#     x_train, y_train, batch_size=2,\n",
    "#     data_gen_args=dict(\n",
    "#         rotation_range=0.,\n",
    "#         width_shift_range=0.00,\n",
    "#         height_shift_range=0.00,\n",
    "#         shear_range=0,\n",
    "#         zoom_range=0.0,\n",
    "#         horizontal_flip=True,\n",
    "#         vertical_flip=True,\n",
    "#         fill_mode='constant'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# del x_train\n",
    "# del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_batch = next(train_gen)\n",
    "\n",
    "xx, yy = sample_batch\n",
    "\n",
    "if NETWORK_HEADS > 1:\n",
    "    yy = yy[0]\n",
    "\n",
    "print(xx.shape, yy.shape)\n",
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "\n",
    "# def preprocess_transform(ds):\n",
    "#     return (ds / MAX_X).astype('float32')\n",
    "\n",
    "# xx = preprocess_transform(xx)\n",
    "# yy = preprocess_transform(yy)\n",
    "\n",
    "print(xx.min())\n",
    "print(xx.max())\n",
    "print(yy.min())\n",
    "print(yy.max())\n",
    "\n",
    "plot_imgs(org_imgs=rgb_transform(xx), mask_imgs=yy, nm_img_to_plot=2, figsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from usquarednet import u2netp_block, u2net_block\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_unet():\n",
    "    inputs = Input(input_shape)\n",
    "    sides = u2net_block(\n",
    "        inputs,\n",
    "        inter_enc_dropout = 0.0,\n",
    "        inter_dec_dropout = 0.0,\n",
    "        enc_intra_enc_dropout = 0.0,\n",
    "        enc_intra_dec_dropout = 0.0,\n",
    "        dec_intra_enc_dropout = 0.0,\n",
    "        dec_intra_dec_dropout = 0.0,\n",
    "    )\n",
    "    model = Model(inputs=[inputs], outputs=sides)\n",
    "    return model\n",
    "\n",
    "def create_unetp():\n",
    "    inputs = Input(input_shape)\n",
    "    sides = u2netp_block(inputs)\n",
    "    model = Model(inputs=[inputs], outputs=sides)\n",
    "    return model\n",
    "\n",
    "model = create_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bcdunet import BCDU_net_D3, BCDU_net_D1\n",
    "\n",
    "# input_shape = (512, 512, 3)\n",
    "# model = BCDU_net_D3(input_size=input_shape, afunc='swish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras_unet.models import custom_unet\n",
    "\n",
    "# # input_shape = (512, 512, 6)\n",
    "\n",
    "def create_model_unet():\n",
    "    model = custom_unet(\n",
    "        input_shape,\n",
    "        filters=8,\n",
    "        activation='swish',\n",
    "        use_batch_norm=True,\n",
    "        dropout=0.5,  # 0.3\n",
    "        dropout_change_per_layer=0.0,\n",
    "        use_attention=False,\n",
    "        use_squeeze_on_enc=False,\n",
    "        use_squeeze_on_dec=False,\n",
    "        num_layers=5,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# model = create_model_unet()\n",
    "\n",
    "# model = custom_unet(\n",
    "#     input_shape,\n",
    "#     filters=32,\n",
    "#     use_batch_norm=True,\n",
    "#     dropout=0.5,  # 0.3\n",
    "#     dropout_change_per_layer=0.0,\n",
    "#     use_attention=False,\n",
    "#     use_squeeze_on_enc=True,\n",
    "#     use_squeeze_on_dec=True,\n",
    "#     num_layers=5,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_trainchpt.h5'\n",
    "callback_checkpoint = ModelCheckpoint(\n",
    "    model_filename, \n",
    "    verbose=1, \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance\n",
    "from AdaBelief_tf import AdaBeliefOptimizer\n",
    "\n",
    "STEPS_PER_EPOCH = train_len // BATCH_SIZE\n",
    "\n",
    "adabelief = AdaBeliefOptimizer(learning_rate=0.0001)\n",
    "ranger = tfa.optimizers.Lookahead(adabelief, sync_period=6, slow_step_size=0.5)\n",
    "\n",
    "model.compile(\n",
    "#     optimizer=Adam(learning_rate=0.001),\n",
    "    optimizer=AdaBeliefOptimizer(learning_rate=0.001, total_steps=300 * STEPS_PER_EPOCH, warmup_proportion=0.03, min_lr=1e-5),\n",
    "#     optimizer=adabelief,\n",
    "    loss=NETWORK_HEADS * ['binary_crossentropy'],\n",
    "    metrics=[iou, iou_thresholded],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#     initial_epoch=220,\n",
    "    epochs=300,\n",
    "    validation_data=(x_val_tf, y_val_tf),\n",
    "    validation_batch_size=BATCH_SIZE,\n",
    "    callbacks=[callback_checkpoint, tensorboard_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "plot_segm_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_trainafter.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(model_filename)\n",
    "# model.save('model.h5')\n",
    "model.load_weights('model_trainchpt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "if NETWORK_HEADS > 1:\n",
    "    y_pred = y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "display(len(x_val))\n",
    "plot_imgs(org_imgs=rgb_transform(x_val), mask_imgs=y_val, pred_imgs=y_pred, nm_img_to_plot=10, figsize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
