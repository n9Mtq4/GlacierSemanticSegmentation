{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/karolzak/keras-unet/blob/master/notebooks/kz-whale-tails.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data/tiles/ls78\")\n",
    "\n",
    "MAX_X = 255\n",
    "MAX_Y = 65535  # TODO: Tilegen outputs rgb image, not grayscale\n",
    "\n",
    "BAND_DIRS = sorted(list(DATA_DIR.glob(\"B*\")))\n",
    "TRUTH_DIR = DATA_DIR / \"truth\"\n",
    "\n",
    "display(BAND_DIRS)\n",
    "display(list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_paths = list(TRUTH_DIR.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fname(fname):\n",
    "    # div by maxy, but mul by maxx in anticipation of preprocess_transform\n",
    "    truth = np.array(Image.open(TRUTH_DIR / fname)) / (MAX_Y / MAX_X)\n",
    "    truth = truth.astype('uint8')\n",
    "    bands = np.asarray([np.array(Image.open(band_dir / fname)) for band_dir in BAND_DIRS])\n",
    "#     bands = bands[1:4][::-1]\n",
    "    mchannel = np.dstack(bands).astype('uint8')\n",
    "    return mchannel, truth\n",
    "\n",
    "def preprocess_transform(ds):\n",
    "    return (ds / MAX_X).astype('float32')\n",
    "\n",
    "def rgb_transform(ds):\n",
    "#     return np.flip(ds, 3)  # Bands 2, 3, 4 -> rgb\n",
    "    return np.flip(ds[:,:,:,1:4], 3)  # Bands 1, 2, 3, 4, 5, 7 -> rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(truth_paths[0].name)\n",
    "\n",
    "x0, y0 = read_fname(truth_paths[0].name)\n",
    "\n",
    "display(x0.shape)\n",
    "display(y0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_lst = []\n",
    "msk_lst = []\n",
    "\n",
    "for truth_path in truth_paths:\n",
    "    img, truth = read_fname(truth_path.name)\n",
    "    img_lst.append(img)\n",
    "    msk_lst.append(truth)\n",
    "\n",
    "img_np = np.asarray(img_lst)\n",
    "msk_np = np.asarray(msk_lst)\n",
    "msk_np = msk_np.reshape(msk_np.shape[0], msk_np.shape[1], msk_np.shape[2], 1)\n",
    "\n",
    "del img_lst\n",
    "del msk_lst\n",
    "\n",
    "display(f'{img_np.shape=}')\n",
    "display(f'{msk_np.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "display(img_np.min())\n",
    "display(img_np.max())\n",
    "display(msk_np.min())\n",
    "display(msk_np.max())\n",
    "\n",
    "plot_imgs(org_imgs=rgb_transform(img_np) / 255, mask_imgs=msk_np / 255, nm_img_to_plot=5, figsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(img_np, msk_np, test_size=0.30, random_state=0)\n",
    "\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_val: \", x_val.shape)\n",
    "print(\"y_val: \", y_val.shape)\n",
    "\n",
    "input_shape = x_train[0].shape\n",
    "display(f'{input_shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = preprocess_transform(x_val)\n",
    "y_val = preprocess_transform(y_val)\n",
    "\n",
    "x_val_tf = tf.convert_to_tensor(x_val)\n",
    "y_val_tf = tf.convert_to_tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import get_augmented\n",
    "\n",
    "train_gen = get_augmented(\n",
    "    x_train, y_train, \n",
    "#     x_val_tf, y_val_tf,\n",
    "    batch_size=2,\n",
    "    data_gen_args = dict(\n",
    "#         rescale=1 / 255,\n",
    "        preprocessing_function=preprocess_transform,\n",
    "        rotation_range=360.,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=40,\n",
    "        zoom_range=0.2,\n",
    "#         brightness_range=[0.7,1.4],  # only works on 1 or 3 channel images\n",
    "        channel_shift_range=10.0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect'\n",
    "    ))\n",
    "\n",
    "# train_gen = get_augmented(\n",
    "#     x_train, y_train, batch_size=2,\n",
    "#     data_gen_args=dict(\n",
    "#         rotation_range=0.,\n",
    "#         width_shift_range=0.00,\n",
    "#         height_shift_range=0.00,\n",
    "#         shear_range=0,\n",
    "#         zoom_range=0.0,\n",
    "#         horizontal_flip=True,\n",
    "#         vertical_flip=True,\n",
    "#         fill_mode='constant'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_batch = next(train_gen)\n",
    "\n",
    "xx, yy = sample_batch\n",
    "print(xx.shape, yy.shape)\n",
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "plot_imgs(org_imgs=rgb_transform(xx), mask_imgs=yy, nm_img_to_plot=2, figsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/biomedical-image-segmentation-unet-991d075a3a4b\n",
    "\n",
    "class conv_block_nested(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super(conv_block_nested, self).__init__()\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_ch)\n",
    "        self.conv2 = nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        output = self.activation(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "class Nested_UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, out_ch=1):\n",
    "        super(Nested_UNet, self).__init__()\n",
    "\n",
    "        n1 = 512\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0])\n",
    "        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])\n",
    "        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])\n",
    "        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])\n",
    "        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])\n",
    "\n",
    "        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])\n",
    "        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])\n",
    "        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])\n",
    "        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])\n",
    "\n",
    "        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])\n",
    "        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])\n",
    "        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])\n",
    "\n",
    "        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])\n",
    "        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])\n",
    "\n",
    "        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])\n",
    "\n",
    "        self.final = nn.Conv2d(filters[0], out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.Up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.Up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.Up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.Up(x1_3)], 1))\n",
    "\n",
    "        output = self.final(x0_4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = Nested_UNet(in_ch=6)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_gen, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = np.moveaxis(inputs, 3, 1)\n",
    "        inputs = torch.from_numpy(inputs)\n",
    "        labels = torch.from_numpy(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        del inputs\n",
    "        del labels\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_trainchpt.h5'\n",
    "callback_checkpoint = ModelCheckpoint(\n",
    "    model_filename, \n",
    "    verbose=1, \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance\n",
    "\n",
    "def closs(y_true, y_pred):\n",
    "    return 3 * jaccard_distance(y_true, y_pred) + tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001 * 10),\n",
    "    #optimizer=SGD(lr=0.01, momentum=0.99),\n",
    "    loss='binary_crossentropy',\n",
    "#     loss=jaccard_distance,\n",
    "#     loss=closs,\n",
    "    metrics=[iou, iou_thresholded]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=500,\n",
    "    \n",
    "    validation_data=(x_val_tf, y_val_tf),\n",
    "    validation_batch_size=2,\n",
    "    callbacks=[callback_checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "plot_segm_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "display(len(x_val))\n",
    "plot_imgs(org_imgs=rgb_transform(x_val), mask_imgs=y_val, pred_imgs=y_pred, nm_img_to_plot=10, figsize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
